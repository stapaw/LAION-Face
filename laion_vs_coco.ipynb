{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stanislaw/PycharmProjects/LAION-Face/venv/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Using cache found in /home/stanislaw/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "# input_image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from retinaface import RetinaFace\n",
    "import numpy as np\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtering imgs containing faces in MSCOCO and mv it to other folder. (ignoring all errors, e.g. not 3-channel images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 11/386 [00:13<05:40,  1.10it/s]"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in tqdm(range(13076, 15005, 5)):\n",
    "    try:\n",
    "        path = f\"mscoco_face_data/split_00000/00001/{str(i).zfill(9)}.jpg\"\n",
    "        resp = RetinaFace.detect_faces(path)\n",
    "        if np.any([resp[face]['score'] for face in resp]) > 0.9:\n",
    "            shutil.move(path, f'{path.split(\"/\")[0]}/face/{path.split(\"/\")[-1]}')\n",
    "            count +=1\n",
    "    except:\n",
    "        pass\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9995817542076111]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[resp[face]['score'] for face in resp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_batch = []\n",
    "#coco\n",
    "for filename in glob.iglob(f'./mscoco_face_data/face/*'):\n",
    "    try:\n",
    "        input_image = Image.open(filename)\n",
    "        preprocess = transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "        input_tensor = preprocess(input_image)\n",
    "        img_batch += input_tensor.unsqueeze(0)\n",
    "    except:\n",
    "        pass\n",
    "#laion\n",
    "for i in range(0, 167):\n",
    "    try:\n",
    "        input_image = Image.open(f\"laion_face_data/split_00000/00000/{str(i).zfill(9)}.jpg\")\n",
    "    \n",
    "        preprocess = transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "        input_tensor = preprocess(input_image)\n",
    "        img_batch += input_tensor.unsqueeze(0)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "img_batch = torch.stack([*img_batch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([286, 3, 224, 224])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:05<00:00,  5.33it/s]\n"
     ]
    }
   ],
   "source": [
    "# input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model\n",
    "\n",
    "# move the input and model to GPU for speed if available\n",
    "output = []\n",
    "# if torch.cuda.is_available():\n",
    "#     model.to('cuda')\n",
    "for i in tqdm(range(0, 290, 10)):\n",
    "    input_batch = img_batch[i:i+10]\n",
    "#     input_batch = input_batch.to('cuda')\n",
    "    with torch.no_grad():\n",
    "        output += model(input_batch)\n",
    "\n",
    "output = torch.stack([*output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([286, 1000])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used to create data for viz in https://projector.tensorflow.org/\n",
    "import pandas as pd\n",
    "t=output\n",
    "t_np = t.cpu().numpy() #convert to Numpy array\n",
    "df = pd.DataFrame(t_np) #convert to a dataframe\n",
    "df.to_csv(\"testfile.tsv\",index=False, sep=\"\\t\", header=False) #save to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_OF_IMG_IN_1ST_DATASET =143\n",
    "df['i']= df.index > NUMBER_OF_IMG_IN_1ST_DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['i'].to_csv(\"labels.tsv\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>991</th>\n",
       "      <th>992</th>\n",
       "      <th>993</th>\n",
       "      <th>994</th>\n",
       "      <th>995</th>\n",
       "      <th>996</th>\n",
       "      <th>997</th>\n",
       "      <th>998</th>\n",
       "      <th>999</th>\n",
       "      <th>i</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.042199</td>\n",
       "      <td>1.666004</td>\n",
       "      <td>1.568521</td>\n",
       "      <td>1.650911</td>\n",
       "      <td>1.586255</td>\n",
       "      <td>2.484907</td>\n",
       "      <td>2.846426</td>\n",
       "      <td>-1.661567</td>\n",
       "      <td>-2.239351</td>\n",
       "      <td>-5.042858</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.983123</td>\n",
       "      <td>-2.128247</td>\n",
       "      <td>-5.320333</td>\n",
       "      <td>0.240097</td>\n",
       "      <td>-2.150342</td>\n",
       "      <td>-1.685590</td>\n",
       "      <td>0.121385</td>\n",
       "      <td>0.928128</td>\n",
       "      <td>4.590708</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-3.557405</td>\n",
       "      <td>-0.391183</td>\n",
       "      <td>-3.935380</td>\n",
       "      <td>-3.073274</td>\n",
       "      <td>-1.541572</td>\n",
       "      <td>-1.344232</td>\n",
       "      <td>-1.192342</td>\n",
       "      <td>0.894013</td>\n",
       "      <td>-1.313890</td>\n",
       "      <td>-3.197292</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.279642</td>\n",
       "      <td>-4.122759</td>\n",
       "      <td>-3.515110</td>\n",
       "      <td>-3.208604</td>\n",
       "      <td>-2.717437</td>\n",
       "      <td>-0.677198</td>\n",
       "      <td>-2.210864</td>\n",
       "      <td>-2.066689</td>\n",
       "      <td>6.259179</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.732625</td>\n",
       "      <td>-1.538850</td>\n",
       "      <td>-2.989211</td>\n",
       "      <td>-6.986698</td>\n",
       "      <td>-3.214403</td>\n",
       "      <td>-2.543644</td>\n",
       "      <td>-4.121750</td>\n",
       "      <td>1.880281</td>\n",
       "      <td>3.037087</td>\n",
       "      <td>-0.508553</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.579668</td>\n",
       "      <td>-0.724722</td>\n",
       "      <td>-0.664674</td>\n",
       "      <td>-1.556822</td>\n",
       "      <td>-0.281095</td>\n",
       "      <td>1.602777</td>\n",
       "      <td>-0.946723</td>\n",
       "      <td>1.002028</td>\n",
       "      <td>2.886131</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.268174</td>\n",
       "      <td>-3.392117</td>\n",
       "      <td>0.447099</td>\n",
       "      <td>-0.462099</td>\n",
       "      <td>-1.508214</td>\n",
       "      <td>-1.567885</td>\n",
       "      <td>-0.886254</td>\n",
       "      <td>0.708687</td>\n",
       "      <td>0.072315</td>\n",
       "      <td>1.511860</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.953819</td>\n",
       "      <td>-2.851128</td>\n",
       "      <td>-1.926602</td>\n",
       "      <td>-1.519792</td>\n",
       "      <td>-2.445457</td>\n",
       "      <td>0.467408</td>\n",
       "      <td>-2.101395</td>\n",
       "      <td>0.254803</td>\n",
       "      <td>1.548754</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.263749</td>\n",
       "      <td>-4.440587</td>\n",
       "      <td>-1.158522</td>\n",
       "      <td>-2.686519</td>\n",
       "      <td>-2.138419</td>\n",
       "      <td>-4.611231</td>\n",
       "      <td>-3.895607</td>\n",
       "      <td>0.796442</td>\n",
       "      <td>-0.541820</td>\n",
       "      <td>2.452530</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.414467</td>\n",
       "      <td>-3.708502</td>\n",
       "      <td>-4.860530</td>\n",
       "      <td>-3.136843</td>\n",
       "      <td>-2.958047</td>\n",
       "      <td>-2.633459</td>\n",
       "      <td>-3.996073</td>\n",
       "      <td>0.269483</td>\n",
       "      <td>0.835155</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>3.742020</td>\n",
       "      <td>-0.824134</td>\n",
       "      <td>-0.026026</td>\n",
       "      <td>0.264265</td>\n",
       "      <td>0.801854</td>\n",
       "      <td>-0.365111</td>\n",
       "      <td>0.658960</td>\n",
       "      <td>-1.408317</td>\n",
       "      <td>-2.503309</td>\n",
       "      <td>-0.678806</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.780777</td>\n",
       "      <td>-3.089402</td>\n",
       "      <td>-2.131645</td>\n",
       "      <td>-0.176030</td>\n",
       "      <td>-2.828650</td>\n",
       "      <td>-0.783943</td>\n",
       "      <td>0.221712</td>\n",
       "      <td>1.490485</td>\n",
       "      <td>2.184805</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>1.127660</td>\n",
       "      <td>-1.434879</td>\n",
       "      <td>0.192641</td>\n",
       "      <td>-1.385619</td>\n",
       "      <td>1.268991</td>\n",
       "      <td>-1.124739</td>\n",
       "      <td>-2.175979</td>\n",
       "      <td>0.986479</td>\n",
       "      <td>-0.990430</td>\n",
       "      <td>0.302945</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.015771</td>\n",
       "      <td>-3.237227</td>\n",
       "      <td>-0.279458</td>\n",
       "      <td>-0.251598</td>\n",
       "      <td>-1.055005</td>\n",
       "      <td>-0.795737</td>\n",
       "      <td>-0.733964</td>\n",
       "      <td>2.307082</td>\n",
       "      <td>2.245730</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>-1.843122</td>\n",
       "      <td>-0.527434</td>\n",
       "      <td>-1.966538</td>\n",
       "      <td>-2.560517</td>\n",
       "      <td>-1.747687</td>\n",
       "      <td>-2.513512</td>\n",
       "      <td>-4.364317</td>\n",
       "      <td>-0.294093</td>\n",
       "      <td>-3.212142</td>\n",
       "      <td>-3.892242</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.949220</td>\n",
       "      <td>-1.440389</td>\n",
       "      <td>-3.932070</td>\n",
       "      <td>-2.128608</td>\n",
       "      <td>-4.296507</td>\n",
       "      <td>-1.822982</td>\n",
       "      <td>-5.117743</td>\n",
       "      <td>0.183965</td>\n",
       "      <td>3.046900</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>-3.965820</td>\n",
       "      <td>-2.187596</td>\n",
       "      <td>1.363854</td>\n",
       "      <td>-2.315587</td>\n",
       "      <td>-0.651931</td>\n",
       "      <td>0.877066</td>\n",
       "      <td>-1.638174</td>\n",
       "      <td>-1.579365</td>\n",
       "      <td>-3.465210</td>\n",
       "      <td>-3.055721</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.856341</td>\n",
       "      <td>-1.468276</td>\n",
       "      <td>-3.639595</td>\n",
       "      <td>-3.832289</td>\n",
       "      <td>-2.670493</td>\n",
       "      <td>-1.253663</td>\n",
       "      <td>-4.749150</td>\n",
       "      <td>-2.498746</td>\n",
       "      <td>2.180613</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>-3.477053</td>\n",
       "      <td>-4.746140</td>\n",
       "      <td>-4.372375</td>\n",
       "      <td>-5.809248</td>\n",
       "      <td>-3.733397</td>\n",
       "      <td>-2.103674</td>\n",
       "      <td>-3.749898</td>\n",
       "      <td>0.246179</td>\n",
       "      <td>-1.868017</td>\n",
       "      <td>0.012107</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.292630</td>\n",
       "      <td>-6.589329</td>\n",
       "      <td>-3.947448</td>\n",
       "      <td>-5.192978</td>\n",
       "      <td>-4.441269</td>\n",
       "      <td>-3.550370</td>\n",
       "      <td>-4.586531</td>\n",
       "      <td>-0.750250</td>\n",
       "      <td>1.211887</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>286 rows × 1001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "0    0.042199  1.666004  1.568521  1.650911  1.586255  2.484907  2.846426   \n",
       "1   -3.557405 -0.391183 -3.935380 -3.073274 -1.541572 -1.344232 -1.192342   \n",
       "2   -2.732625 -1.538850 -2.989211 -6.986698 -3.214403 -2.543644 -4.121750   \n",
       "3   -2.268174 -3.392117  0.447099 -0.462099 -1.508214 -1.567885 -0.886254   \n",
       "4   -1.263749 -4.440587 -1.158522 -2.686519 -2.138419 -4.611231 -3.895607   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "281  3.742020 -0.824134 -0.026026  0.264265  0.801854 -0.365111  0.658960   \n",
       "282  1.127660 -1.434879  0.192641 -1.385619  1.268991 -1.124739 -2.175979   \n",
       "283 -1.843122 -0.527434 -1.966538 -2.560517 -1.747687 -2.513512 -4.364317   \n",
       "284 -3.965820 -2.187596  1.363854 -2.315587 -0.651931  0.877066 -1.638174   \n",
       "285 -3.477053 -4.746140 -4.372375 -5.809248 -3.733397 -2.103674 -3.749898   \n",
       "\n",
       "            7         8         9  ...       991       992       993  \\\n",
       "0   -1.661567 -2.239351 -5.042858  ... -3.983123 -2.128247 -5.320333   \n",
       "1    0.894013 -1.313890 -3.197292  ... -5.279642 -4.122759 -3.515110   \n",
       "2    1.880281  3.037087 -0.508553  ... -0.579668 -0.724722 -0.664674   \n",
       "3    0.708687  0.072315  1.511860  ... -3.953819 -2.851128 -1.926602   \n",
       "4    0.796442 -0.541820  2.452530  ... -4.414467 -3.708502 -4.860530   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "281 -1.408317 -2.503309 -0.678806  ... -2.780777 -3.089402 -2.131645   \n",
       "282  0.986479 -0.990430  0.302945  ... -3.015771 -3.237227 -0.279458   \n",
       "283 -0.294093 -3.212142 -3.892242  ... -3.949220 -1.440389 -3.932070   \n",
       "284 -1.579365 -3.465210 -3.055721  ... -3.856341 -1.468276 -3.639595   \n",
       "285  0.246179 -1.868017  0.012107  ... -5.292630 -6.589329 -3.947448   \n",
       "\n",
       "          994       995       996       997       998       999      i  \n",
       "0    0.240097 -2.150342 -1.685590  0.121385  0.928128  4.590708  False  \n",
       "1   -3.208604 -2.717437 -0.677198 -2.210864 -2.066689  6.259179  False  \n",
       "2   -1.556822 -0.281095  1.602777 -0.946723  1.002028  2.886131  False  \n",
       "3   -1.519792 -2.445457  0.467408 -2.101395  0.254803  1.548754  False  \n",
       "4   -3.136843 -2.958047 -2.633459 -3.996073  0.269483  0.835155  False  \n",
       "..        ...       ...       ...       ...       ...       ...    ...  \n",
       "281 -0.176030 -2.828650 -0.783943  0.221712  1.490485  2.184805   True  \n",
       "282 -0.251598 -1.055005 -0.795737 -0.733964  2.307082  2.245730   True  \n",
       "283 -2.128608 -4.296507 -1.822982 -5.117743  0.183965  3.046900   True  \n",
       "284 -3.832289 -2.670493 -1.253663 -4.749150 -2.498746  2.180613   True  \n",
       "285 -5.192978 -4.441269 -3.550370 -4.586531 -0.750250  1.211887   True  \n",
       "\n",
       "[286 rows x 1001 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hand-crafted size of img_batch (some ids are filtered out in preproc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_batch = []\n",
    "for i in range(0, 167):\n",
    "    try:\n",
    "        input_image = Image.open(f\"laion_face_data/split_00000/00000/{str(i).zfill(9)}.jpg\")\n",
    "    \n",
    "        preprocess = transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "        input_tensor = preprocess(input_image)\n",
    "        img_batch += input_tensor.unsqueeze(0)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "img_batch = torch.stack([*img_batch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([286, 3, 224, 224])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_batch = []\n",
    "for filename in glob.iglob(f'./mscoco_face_data/face/*'):\n",
    "    try:\n",
    "        input_image = Image.open(filename)\n",
    "        preprocess = transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "        input_tensor = preprocess(input_image)\n",
    "        img_batch += input_tensor.unsqueeze(0)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "img_batch = torch.stack([*img_batch])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
